{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/21 14:27:54 WARN Utils: Your hostname, Ala resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "24/12/21 14:27:54 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ala/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ala/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-745fc576-e06a-44e3-ac61-723b50081b54;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.3.0 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.3.0 in central\n",
      "\tfound org.apache.kafka#kafka-clients;2.8.1 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.8.4 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.32 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.2 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.2 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
      ":: resolution report :: resolve 405ms :: artifacts dl 17ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.2 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;2.8.1 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.3.0 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.3.0 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.32 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.8.4 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   12  |   0   |   0   |   0   ||   12  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-745fc576-e06a-44e3-ac61-723b50081b54\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 12 already retrieved (0kB/6ms)\n",
      "24/12/21 14:27:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "%run \"SparkApp.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = StructType([\n",
    "    StructField(\"id\", StringType(), True),  # Le champ 'id' est une chaîne\n",
    "    StructField(\"tripUpdate\", StructType([  # Le champ 'tripUpdate' est un objet imbriqué\n",
    "        StructField(\"trip\", StructType([  # Le champ 'trip' est aussi un objet imbriqué\n",
    "            StructField(\"tripId\", StringType(), True),\n",
    "            StructField(\"startTime\", StringType(), True),\n",
    "            StructField(\"startDate\", StringType(), True),\n",
    "            StructField(\"scheduleRelationship\", StringType(), True),\n",
    "            StructField(\"routeId\", StringType(), True),\n",
    "            StructField(\"directionId\", LongType(), True)  # Utilisation de LongType pour les entiers longs\n",
    "        ]), True),\n",
    "        StructField(\"stopTimeUpdate\", ArrayType(  # Le champ 'stopTimeUpdate' est un tableau\n",
    "            StructType([  # Chaque élément du tableau est un objet\n",
    "                StructField(\"stopSequence\", LongType(), True),\n",
    "                StructField(\"departure\", StructType([  # Le champ 'departure' est un objet imbriqué\n",
    "                    StructField(\"time\", StringType(), True)\n",
    "                ]), True),\n",
    "                StructField(\"stopId\", StringType(), True),\n",
    "                StructField(\"scheduleRelationship\", StringType(), True)\n",
    "            ])\n",
    "        ), True)\n",
    "    ]), True),\n",
    "    StructField(\"timestamp\", StringType(), True)  # Le champ 'timestamp' est une chaîne\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"subscribe\", \"tripupdate\") \\\n",
    "    .option(\"startingOffsets\",\"earliest\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kafka_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "kafka_json_df = kafka_df.withColumn(\"value\", expr(\"cast(value as string)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_json,col\n",
    "\n",
    "streaming_df = kafka_json_df.withColumn(\"values_json\", from_json(col(\"value\"), json_schema)).selectExpr(\"values_json.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- tripUpdate: struct (nullable = true)\n",
      " |    |-- trip: struct (nullable = true)\n",
      " |    |    |-- tripId: string (nullable = true)\n",
      " |    |    |-- startTime: string (nullable = true)\n",
      " |    |    |-- startDate: string (nullable = true)\n",
      " |    |    |-- scheduleRelationship: string (nullable = true)\n",
      " |    |    |-- routeId: string (nullable = true)\n",
      " |    |    |-- directionId: long (nullable = true)\n",
      " |    |-- stopTimeUpdate: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- stopSequence: long (nullable = true)\n",
      " |    |    |    |-- departure: struct (nullable = true)\n",
      " |    |    |    |    |-- time: string (nullable = true)\n",
      " |    |    |    |-- stopId: string (nullable = true)\n",
      " |    |    |    |-- scheduleRelationship: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "streaming_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "exploded_df = streaming_df.withColumn(\"tripUpdate_stopTimeUpdate\", explode(\"tripUpdate.stopTimeUpdate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- tripUpdate: struct (nullable = true)\n",
      " |    |-- trip: struct (nullable = true)\n",
      " |    |    |-- tripId: string (nullable = true)\n",
      " |    |    |-- startTime: string (nullable = true)\n",
      " |    |    |-- startDate: string (nullable = true)\n",
      " |    |    |-- scheduleRelationship: string (nullable = true)\n",
      " |    |    |-- routeId: string (nullable = true)\n",
      " |    |    |-- directionId: long (nullable = true)\n",
      " |    |-- stopTimeUpdate: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- stopSequence: long (nullable = true)\n",
      " |    |    |    |-- departure: struct (nullable = true)\n",
      " |    |    |    |    |-- time: string (nullable = true)\n",
      " |    |    |    |-- stopId: string (nullable = true)\n",
      " |    |    |    |-- scheduleRelationship: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- tripUpdate_stopTimeUpdate: struct (nullable = true)\n",
      " |    |-- stopSequence: long (nullable = true)\n",
      " |    |-- departure: struct (nullable = true)\n",
      " |    |    |-- time: string (nullable = true)\n",
      " |    |-- stopId: string (nullable = true)\n",
      " |    |-- scheduleRelationship: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exploded_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `exploded_stopTimeUpdate`.`stopSequence` cannot be resolved. Did you mean one of the following? [`tripUpdate_stopTimeUpdate`, `tripUpdate`, `timestamp`, `id`].;\n'Project [id#203, timestamp#205, tripUpdate#204.trip.tripId AS tripId#233, tripUpdate#204.trip.startTime AS startTime#234, tripUpdate#204.trip.startDate AS startDate#235, tripUpdate#204.trip.scheduleRelationship AS scheduleRelationship#236, tripUpdate#204.trip.routeId AS routeId#237, tripUpdate#204.trip.directionId AS directionId#238L, 'exploded_stopTimeUpdate.stopSequence, 'exploded_stopTimeUpdate.departure.time, 'exploded_stopTimeUpdate.stopId, 'exploded_stopTimeUpdate.scheduleRelationship]\n+- Project [id#203, tripUpdate#204, timestamp#205, tripUpdate_stopTimeUpdate#213]\n   +- Generate explode(tripUpdate#204.stopTimeUpdate), false, [tripUpdate_stopTimeUpdate#213]\n      +- Project [values_json#194.id AS id#203, values_json#194.tripUpdate AS tripUpdate#204, values_json#194.timestamp AS timestamp#205]\n         +- Project [key#144, value#185, topic#146, partition#147, offset#148L, timestamp#149, timestampType#150, from_json(StructField(id,StringType,true), StructField(tripUpdate,StructType(StructField(trip,StructType(StructField(tripId,StringType,true),StructField(startTime,StringType,true),StructField(startDate,StringType,true),StructField(scheduleRelationship,StringType,true),StructField(routeId,StringType,true),StructField(directionId,LongType,true)),true),StructField(stopTimeUpdate,ArrayType(StructType(StructField(stopSequence,LongType,true),StructField(departure,StructType(StructField(time,StringType,true)),true),StructField(stopId,StringType,true),StructField(scheduleRelationship,StringType,true)),true),true)),true), StructField(timestamp,StringType,true), value#185, Some(Europe/Paris)) AS values_json#194]\n            +- Project [key#144, cast(value#145 as string) AS value#185, topic#146, partition#147, offset#148L, timestamp#149, timestampType#150]\n               +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@33595cc7, kafka, org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@5e0a8d48, [startingOffsets=earliest, kafka.bootstrap.servers=localhost:9092, subscribe=tripupdate], [key#144, value#145, topic#146, partition#147, offset#148L, timestamp#149, timestampType#150], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@efa1b6f,kafka,List(),None,List(),None,Map(kafka.bootstrap.servers -> localhost:9092, subscribe -> tripupdate, startingOffsets -> earliest),None), kafka, [key#137, value#138, topic#139, partition#140, offset#141L, timestamp#142, timestampType#143]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m selected_df \u001b[38;5;241m=\u001b[39m \u001b[43mexploded_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimestamp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtripUpdate.trip.tripId\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtripUpdate.trip.startTime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtripUpdate.trip.startDate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtripUpdate.trip.scheduleRelationship\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtripUpdate.trip.routeId\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtripUpdate.trip.directionId\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexploded_stopTimeUpdate.stopSequence\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexploded_stopTimeUpdate.departure.time\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexploded_stopTimeUpdate.stopId\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexploded_stopTimeUpdate.scheduleRelationship\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/dataframe.py:3229\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   3184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   3185\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   3186\u001b[0m \n\u001b[1;32m   3187\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3227\u001b[0m \u001b[38;5;124;03m    +-----+---+\u001b[39;00m\n\u001b[1;32m   3228\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3229\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jcols\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `exploded_stopTimeUpdate`.`stopSequence` cannot be resolved. Did you mean one of the following? [`tripUpdate_stopTimeUpdate`, `tripUpdate`, `timestamp`, `id`].;\n'Project [id#203, timestamp#205, tripUpdate#204.trip.tripId AS tripId#233, tripUpdate#204.trip.startTime AS startTime#234, tripUpdate#204.trip.startDate AS startDate#235, tripUpdate#204.trip.scheduleRelationship AS scheduleRelationship#236, tripUpdate#204.trip.routeId AS routeId#237, tripUpdate#204.trip.directionId AS directionId#238L, 'exploded_stopTimeUpdate.stopSequence, 'exploded_stopTimeUpdate.departure.time, 'exploded_stopTimeUpdate.stopId, 'exploded_stopTimeUpdate.scheduleRelationship]\n+- Project [id#203, tripUpdate#204, timestamp#205, tripUpdate_stopTimeUpdate#213]\n   +- Generate explode(tripUpdate#204.stopTimeUpdate), false, [tripUpdate_stopTimeUpdate#213]\n      +- Project [values_json#194.id AS id#203, values_json#194.tripUpdate AS tripUpdate#204, values_json#194.timestamp AS timestamp#205]\n         +- Project [key#144, value#185, topic#146, partition#147, offset#148L, timestamp#149, timestampType#150, from_json(StructField(id,StringType,true), StructField(tripUpdate,StructType(StructField(trip,StructType(StructField(tripId,StringType,true),StructField(startTime,StringType,true),StructField(startDate,StringType,true),StructField(scheduleRelationship,StringType,true),StructField(routeId,StringType,true),StructField(directionId,LongType,true)),true),StructField(stopTimeUpdate,ArrayType(StructType(StructField(stopSequence,LongType,true),StructField(departure,StructType(StructField(time,StringType,true)),true),StructField(stopId,StringType,true),StructField(scheduleRelationship,StringType,true)),true),true)),true), StructField(timestamp,StringType,true), value#185, Some(Europe/Paris)) AS values_json#194]\n            +- Project [key#144, cast(value#145 as string) AS value#185, topic#146, partition#147, offset#148L, timestamp#149, timestampType#150]\n               +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@33595cc7, kafka, org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@5e0a8d48, [startingOffsets=earliest, kafka.bootstrap.servers=localhost:9092, subscribe=tripupdate], [key#144, value#145, topic#146, partition#147, offset#148L, timestamp#149, timestampType#150], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@efa1b6f,kafka,List(),None,List(),None,Map(kafka.bootstrap.servers -> localhost:9092, subscribe -> tripupdate, startingOffsets -> earliest),None), kafka, [key#137, value#138, topic#139, partition#140, offset#141L, timestamp#142, timestampType#143]\n"
     ]
    }
   ],
   "source": [
    "selected_df = exploded_df.select(\n",
    "    \"id\",\n",
    "    \"timestamp\",\n",
    "    \"tripUpdate.trip.tripId\",\n",
    "    \"tripUpdate.trip.startTime\",\n",
    "    \"tripUpdate.trip.startDate\",\n",
    "    \"tripUpdate.trip.scheduleRelationship\",\n",
    "    \"tripUpdate.trip.routeId\",\n",
    "    \"tripUpdate.trip.directionId\",\n",
    "    \"exploded_stopTimeUpdate.stopSequence\",\n",
    "    \"exploded_stopTimeUpdate.departure.time\",\n",
    "    \"exploded_stopTimeUpdate.stopId\",\n",
    "    \"exploded_stopTimeUpdate.scheduleRelationship\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE] Cannot resolve \"explode(tripUpdate.trip)\" due to data type mismatch: Parameter 1 requires the (\"ARRAY\" or \"MAP\") type, however \"tripUpdate.trip\" has the type \"STRUCT<tripId: STRING, startTime: STRING, startDate: STRING, scheduleRelationship: STRING, routeId: STRING, directionId: BIGINT>\".;\n'Project [id#203, tripUpdate#204, timestamp#205, explode(tripUpdate#204.trip) AS tripUpdate_trip#221]\n+- Project [values_json#194.id AS id#203, values_json#194.tripUpdate AS tripUpdate#204, values_json#194.timestamp AS timestamp#205]\n   +- Project [key#144, value#185, topic#146, partition#147, offset#148L, timestamp#149, timestampType#150, from_json(StructField(id,StringType,true), StructField(tripUpdate,StructType(StructField(trip,StructType(StructField(tripId,StringType,true),StructField(startTime,StringType,true),StructField(startDate,StringType,true),StructField(scheduleRelationship,StringType,true),StructField(routeId,StringType,true),StructField(directionId,LongType,true)),true),StructField(stopTimeUpdate,ArrayType(StructType(StructField(stopSequence,LongType,true),StructField(departure,StructType(StructField(time,StringType,true)),true),StructField(stopId,StringType,true),StructField(scheduleRelationship,StringType,true)),true),true)),true), StructField(timestamp,StringType,true), value#185, Some(Europe/Paris)) AS values_json#194]\n      +- Project [key#144, cast(value#145 as string) AS value#185, topic#146, partition#147, offset#148L, timestamp#149, timestampType#150]\n         +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@33595cc7, kafka, org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@5e0a8d48, [startingOffsets=earliest, kafka.bootstrap.servers=localhost:9092, subscribe=tripupdate], [key#144, value#145, topic#146, partition#147, offset#148L, timestamp#149, timestampType#150], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@efa1b6f,kafka,List(),None,List(),None,Map(kafka.bootstrap.servers -> localhost:9092, subscribe -> tripupdate, startingOffsets -> earliest),None), kafka, [key#137, value#138, topic#139, partition#140, offset#141L, timestamp#142, timestampType#143]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m explode\n\u001b[0;32m----> 3\u001b[0m explodedj\u001b[38;5;241m=\u001b[39m \u001b[43mstreaming_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtripUpdate_trip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtripUpdate.trip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/dataframe.py:5176\u001b[0m, in \u001b[0;36mDataFrame.withColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   5171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, Column):\n\u001b[1;32m   5172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m   5173\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_COLUMN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5174\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(col)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m   5175\u001b[0m     )\n\u001b[0;32m-> 5176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE] Cannot resolve \"explode(tripUpdate.trip)\" due to data type mismatch: Parameter 1 requires the (\"ARRAY\" or \"MAP\") type, however \"tripUpdate.trip\" has the type \"STRUCT<tripId: STRING, startTime: STRING, startDate: STRING, scheduleRelationship: STRING, routeId: STRING, directionId: BIGINT>\".;\n'Project [id#203, tripUpdate#204, timestamp#205, explode(tripUpdate#204.trip) AS tripUpdate_trip#221]\n+- Project [values_json#194.id AS id#203, values_json#194.tripUpdate AS tripUpdate#204, values_json#194.timestamp AS timestamp#205]\n   +- Project [key#144, value#185, topic#146, partition#147, offset#148L, timestamp#149, timestampType#150, from_json(StructField(id,StringType,true), StructField(tripUpdate,StructType(StructField(trip,StructType(StructField(tripId,StringType,true),StructField(startTime,StringType,true),StructField(startDate,StringType,true),StructField(scheduleRelationship,StringType,true),StructField(routeId,StringType,true),StructField(directionId,LongType,true)),true),StructField(stopTimeUpdate,ArrayType(StructType(StructField(stopSequence,LongType,true),StructField(departure,StructType(StructField(time,StringType,true)),true),StructField(stopId,StringType,true),StructField(scheduleRelationship,StringType,true)),true),true)),true), StructField(timestamp,StringType,true), value#185, Some(Europe/Paris)) AS values_json#194]\n      +- Project [key#144, cast(value#145 as string) AS value#185, topic#146, partition#147, offset#148L, timestamp#149, timestampType#150]\n         +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@33595cc7, kafka, org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@5e0a8d48, [startingOffsets=earliest, kafka.bootstrap.servers=localhost:9092, subscribe=tripupdate], [key#144, value#145, topic#146, partition#147, offset#148L, timestamp#149, timestampType#150], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@efa1b6f,kafka,List(),None,List(),None,Map(kafka.bootstrap.servers -> localhost:9092, subscribe -> tripupdate, startingOffsets -> earliest),None), kafka, [key#137, value#138, topic#139, partition#140, offset#141L, timestamp#142, timestampType#143]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "explodedj= streaming_df.withColumn(\"tripUpdate_trip\", explode(\"tripUpdate.trip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "kafka_json_df = kafka_df.withColumn(\"value\", expr(\"cast(value as string)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_json,col\n",
    "\n",
    "streaming_df = kafka_json_df.withColumn(\"values_json\", from_json(col(\"value\"), json_schema)).selectExpr(\"values_json.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- tripUpdate: struct (nullable = true)\n",
      " |    |-- trip: struct (nullable = true)\n",
      " |    |    |-- tripId: string (nullable = true)\n",
      " |    |    |-- startTime: string (nullable = true)\n",
      " |    |    |-- startDate: string (nullable = true)\n",
      " |    |    |-- scheduleRelationship: string (nullable = true)\n",
      " |    |    |-- routeId: string (nullable = true)\n",
      " |    |    |-- directionId: long (nullable = true)\n",
      " |    |-- stopTimeUpdate: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- stopSequence: long (nullable = true)\n",
      " |    |    |    |-- departure: struct (nullable = true)\n",
      " |    |    |    |    |-- time: string (nullable = true)\n",
      " |    |    |    |-- stopId: string (nullable = true)\n",
      " |    |    |    |-- scheduleRelationship: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "streaming_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import unix_timestamp, explode, col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[FIELD_NOT_FOUND] No such struct field `stopId` in `time`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m exploded_df \u001b[38;5;241m=\u001b[39m streaming_df\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstopTimeUpdateElement\u001b[39m\u001b[38;5;124m\"\u001b[39m, explode(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtripUpdate.stopTimeUpdate\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Sélectionner les champs nécessaires dans 'stopTimeUpdateElement'\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m flattened_df \u001b[38;5;241m=\u001b[39m \u001b[43mexploded_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtripUpdate.trip.tripId\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtripUpdate.trip.startTime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstopTimeUpdateElement.stopSequence\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstopTimeUpdateElement.departure.time\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstopTimeUpdateElement.departure.stopId\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstopTimeUpdateElement.departure.scheduleRelationship\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Afficher le résultat\u001b[39;00m\n\u001b[1;32m     15\u001b[0m flattened_df\u001b[38;5;241m.\u001b[39mshow(truncate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/dataframe.py:3229\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   3184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   3185\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   3186\u001b[0m \n\u001b[1;32m   3187\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3227\u001b[0m \u001b[38;5;124;03m    +-----+---+\u001b[39;00m\n\u001b[1;32m   3228\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3229\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jcols\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [FIELD_NOT_FOUND] No such struct field `stopId` in `time`."
     ]
    }
   ],
   "source": [
    "exploded_df = streaming_df.withColumn(\"stopTimeUpdateElement\", explode(col(\"tripUpdate.stopTimeUpdate\")))\n",
    "\n",
    "# Sélectionner les champs nécessaires dans 'stopTimeUpdateElement'\n",
    "flattened_df = exploded_df.select(\n",
    "    \"id\",\n",
    "    \"tripUpdate.trip.tripId\",\n",
    "    \"tripUpdate.trip.startTime\",\n",
    "    \"stopTimeUpdateElement.stopSequence\",\n",
    "    \"stopTimeUpdateElement.departure.time\",\n",
    "    \"stopTimeUpdateElement.departure.stopId\",\n",
    "    \"stopTimeUpdateElement.departure.scheduleRelationship\"\n",
    ")\n",
    "\n",
    "# Afficher le résultat\n",
    "flattened_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df = streaming_df.withColumn(\"data_devices\", explode(\"data.devices\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Queries with streaming sources must be executed with writeStream.start();\nkafka",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 15\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Example: Selecting nested fields within tripUpdate\u001b[39;00m\n\u001b[1;32m      4\u001b[0m selected_df \u001b[38;5;241m=\u001b[39m streaming_df\u001b[38;5;241m.\u001b[39mselect(\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtripUpdate.trip.tripId\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtripUpdate.stopTimeUpdate\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 15\u001b[0m \u001b[43mselected_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtruncate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m query \u001b[38;5;241m=\u001b[39m selected_df\u001b[38;5;241m.\u001b[39mwriteStream \\\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;241m.\u001b[39moutputMode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsole\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Wait for the termination of the stream (e.g., for a few micro-batches)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/dataframe.py:947\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    888\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[1;32m    889\u001b[0m \n\u001b[1;32m    890\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/dataframe.py:978\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m    971\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    972\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    975\u001b[0m         },\n\u001b[1;32m    976\u001b[0m     )\n\u001b[0;32m--> 978\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mint_truncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Queries with streaming sources must be executed with writeStream.start();\nkafka"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Example: Selecting nested fields within tripUpdate\n",
    "selected_df = streaming_df.select(\n",
    "    \"id\",\n",
    "    \"tripUpdate.trip.tripId\",\n",
    "    \"tripUpdate.trip.startTime\",\n",
    "    \"tripUpdate.trip.startDate\",\n",
    "    \"tripUpdate.trip.scheduleRelationship\",\n",
    "    \"tripUpdate.trip.routeId\",\n",
    "    \"tripUpdate.trip.directionId\",\n",
    "    \"tripUpdate.stopTimeUpdate\"\n",
    ")\n",
    "\n",
    "selected_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE] Cannot resolve \"explode(tripUpdate)\" due to data type mismatch: Parameter 1 requires the (\"ARRAY\" or \"MAP\") type, however \"tripUpdate\" has the type \"STRUCT<trip: STRUCT<tripId: STRING, startTime: STRING, startDate: STRING, scheduleRelationship: STRING, routeId: STRING, directionId: BIGINT>, stopTimeUpdate: ARRAY<STRUCT<stopSequence: BIGINT, departure: STRUCT<time: STRING>, stopId: STRING, scheduleRelationship: STRING>>>\".;\n'Project [id#317, tripUpdate#318, timestamp#319, explode(tripUpdate#318) AS tripUpdate_exploded#514]\n+- Project [values_json#308.id AS id#317, values_json#308.tripUpdate AS tripUpdate#318, values_json#308.timestamp AS timestamp#319]\n   +- Project [key#286, value#300, topic#288, partition#289, offset#290L, timestamp#291, timestampType#292, from_json(StructField(id,StringType,true), StructField(tripUpdate,StructType(StructField(trip,StructType(StructField(tripId,StringType,true),StructField(startTime,StringType,true),StructField(startDate,StringType,true),StructField(scheduleRelationship,StringType,true),StructField(routeId,StringType,true),StructField(directionId,LongType,true)),true),StructField(stopTimeUpdate,ArrayType(StructType(StructField(stopSequence,LongType,true),StructField(departure,StructType(StructField(time,StringType,true)),true),StructField(stopId,StringType,true),StructField(scheduleRelationship,StringType,true)),true),true)),true), StructField(timestamp,StringType,true), value#300, Some(Europe/Paris)) AS values_json#308]\n      +- Project [key#286, cast(value#287 as string) AS value#300, topic#288, partition#289, offset#290L, timestamp#291, timestampType#292]\n         +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@323e272d, kafka, org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@540d9411, [startingOffsets=earliest, kafka.bootstrap.servers=localhost:9092, subscribe=tripupdate], [key#286, value#287, topic#288, partition#289, offset#290L, timestamp#291, timestampType#292], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@3f70900f,kafka,List(),None,List(),None,Map(kafka.bootstrap.servers -> localhost:9092, subscribe -> tripupdate, startingOffsets -> earliest),None), kafka, [key#279, value#280, topic#281, partition#282, offset#283L, timestamp#284, timestampType#285]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_exploded \u001b[38;5;241m=\u001b[39m \u001b[43mstreaming_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtripUpdate_exploded\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtripUpdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/dataframe.py:5176\u001b[0m, in \u001b[0;36mDataFrame.withColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   5171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, Column):\n\u001b[1;32m   5172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m   5173\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_COLUMN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5174\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(col)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m   5175\u001b[0m     )\n\u001b[0;32m-> 5176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE] Cannot resolve \"explode(tripUpdate)\" due to data type mismatch: Parameter 1 requires the (\"ARRAY\" or \"MAP\") type, however \"tripUpdate\" has the type \"STRUCT<trip: STRUCT<tripId: STRING, startTime: STRING, startDate: STRING, scheduleRelationship: STRING, routeId: STRING, directionId: BIGINT>, stopTimeUpdate: ARRAY<STRUCT<stopSequence: BIGINT, departure: STRUCT<time: STRING>, stopId: STRING, scheduleRelationship: STRING>>>\".;\n'Project [id#317, tripUpdate#318, timestamp#319, explode(tripUpdate#318) AS tripUpdate_exploded#514]\n+- Project [values_json#308.id AS id#317, values_json#308.tripUpdate AS tripUpdate#318, values_json#308.timestamp AS timestamp#319]\n   +- Project [key#286, value#300, topic#288, partition#289, offset#290L, timestamp#291, timestampType#292, from_json(StructField(id,StringType,true), StructField(tripUpdate,StructType(StructField(trip,StructType(StructField(tripId,StringType,true),StructField(startTime,StringType,true),StructField(startDate,StringType,true),StructField(scheduleRelationship,StringType,true),StructField(routeId,StringType,true),StructField(directionId,LongType,true)),true),StructField(stopTimeUpdate,ArrayType(StructType(StructField(stopSequence,LongType,true),StructField(departure,StructType(StructField(time,StringType,true)),true),StructField(stopId,StringType,true),StructField(scheduleRelationship,StringType,true)),true),true)),true), StructField(timestamp,StringType,true), value#300, Some(Europe/Paris)) AS values_json#308]\n      +- Project [key#286, cast(value#287 as string) AS value#300, topic#288, partition#289, offset#290L, timestamp#291, timestampType#292]\n         +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@323e272d, kafka, org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@540d9411, [startingOffsets=earliest, kafka.bootstrap.servers=localhost:9092, subscribe=tripupdate], [key#286, value#287, topic#288, partition#289, offset#290L, timestamp#291, timestampType#292], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@3f70900f,kafka,List(),None,List(),None,Map(kafka.bootstrap.servers -> localhost:9092, subscribe -> tripupdate, startingOffsets -> earliest),None), kafka, [key#279, value#280, topic#281, partition#282, offset#283L, timestamp#284, timestampType#285]\n"
     ]
    }
   ],
   "source": [
    "df_exploded = streaming_df.withColumn(\"tripUpdate_exploded\", F.explode(\"tripUpdate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_delay = df_exploded.withColumn(\n",
    "    \"departure_delay\",\n",
    "    (unix_timestamp(\"stopTime.departure.time\") - unix_timestamp(\"tripUpdate.trip.startTime\")).cast(\"long\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- tripUpdate: struct (nullable = true)\n",
      " |    |-- trip: struct (nullable = true)\n",
      " |    |    |-- tripId: string (nullable = true)\n",
      " |    |    |-- startTime: string (nullable = true)\n",
      " |    |    |-- startDate: string (nullable = true)\n",
      " |    |    |-- scheduleRelationship: string (nullable = true)\n",
      " |    |    |-- routeId: string (nullable = true)\n",
      " |    |    |-- directionId: long (nullable = true)\n",
      " |    |-- stopTimeUpdate: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- stopSequence: long (nullable = true)\n",
      " |    |    |    |-- departure: struct (nullable = true)\n",
      " |    |    |    |    |-- time: string (nullable = true)\n",
      " |    |    |    |-- stopId: string (nullable = true)\n",
      " |    |    |    |-- scheduleRelationship: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- stopTime: struct (nullable = true)\n",
      " |    |-- stopSequence: long (nullable = true)\n",
      " |    |-- departure: struct (nullable = true)\n",
      " |    |    |-- time: string (nullable = true)\n",
      " |    |-- stopId: string (nullable = true)\n",
      " |    |-- scheduleRelationship: string (nullable = true)\n",
      " |-- departure_delay: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_delay.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_rev = streaming_df.select(\n",
    "    \"id\",\n",
    "    \"tripUpdate.trip.tripId\",\n",
    "    \"tripUpdate.trip.startTime\",\n",
    "    \"tripUpdate.stopTimeUpdate\",\n",
    "    \"timestamp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded = streaming_df.withColumn(\"stopTimeUpdate_exploded\", F.explode(\"tripUpdate.stopTimeUpdate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- tripUpdate: struct (nullable = true)\n",
      " |    |-- trip: struct (nullable = true)\n",
      " |    |    |-- tripId: string (nullable = true)\n",
      " |    |    |-- startTime: string (nullable = true)\n",
      " |    |    |-- startDate: string (nullable = true)\n",
      " |    |    |-- scheduleRelationship: string (nullable = true)\n",
      " |    |    |-- routeId: string (nullable = true)\n",
      " |    |    |-- directionId: long (nullable = true)\n",
      " |    |-- stopTimeUpdate: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- stopSequence: long (nullable = true)\n",
      " |    |    |    |-- departure: struct (nullable = true)\n",
      " |    |    |    |    |-- time: string (nullable = true)\n",
      " |    |    |    |-- stopId: string (nullable = true)\n",
      " |    |    |    |-- scheduleRelationship: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- stopTimeUpdate_exploded: struct (nullable = true)\n",
      " |    |-- stopSequence: long (nullable = true)\n",
      " |    |-- departure: struct (nullable = true)\n",
      " |    |    |-- time: string (nullable = true)\n",
      " |    |-- stopId: string (nullable = true)\n",
      " |    |-- scheduleRelationship: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_exploded.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `tripId` cannot be resolved. Did you mean one of the following? [`id`, `tripUpdate`, `timestamp`, `stopTimeUpdate_exploded`].;\n'Project [id#317, 'tripId, 'startTime, timestamp#319, stopTimeUpdate_exploded#498.stopSequence AS stopSequence#503L, stopTimeUpdate_exploded#498.departure.time AS departure_time#504, stopTimeUpdate_exploded#498.stopId AS stopId#505, stopTimeUpdate_exploded#498.scheduleRelationship AS scheduleRelationship#506]\n+- Project [id#317, tripUpdate#318, timestamp#319, stopTimeUpdate_exploded#498]\n   +- Generate explode(tripUpdate#318.stopTimeUpdate), false, [stopTimeUpdate_exploded#498]\n      +- Project [values_json#308.id AS id#317, values_json#308.tripUpdate AS tripUpdate#318, values_json#308.timestamp AS timestamp#319]\n         +- Project [key#286, value#300, topic#288, partition#289, offset#290L, timestamp#291, timestampType#292, from_json(StructField(id,StringType,true), StructField(tripUpdate,StructType(StructField(trip,StructType(StructField(tripId,StringType,true),StructField(startTime,StringType,true),StructField(startDate,StringType,true),StructField(scheduleRelationship,StringType,true),StructField(routeId,StringType,true),StructField(directionId,LongType,true)),true),StructField(stopTimeUpdate,ArrayType(StructType(StructField(stopSequence,LongType,true),StructField(departure,StructType(StructField(time,StringType,true)),true),StructField(stopId,StringType,true),StructField(scheduleRelationship,StringType,true)),true),true)),true), StructField(timestamp,StringType,true), value#300, Some(Europe/Paris)) AS values_json#308]\n            +- Project [key#286, cast(value#287 as string) AS value#300, topic#288, partition#289, offset#290L, timestamp#291, timestampType#292]\n               +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@323e272d, kafka, org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@540d9411, [startingOffsets=earliest, kafka.bootstrap.servers=localhost:9092, subscribe=tripupdate], [key#286, value#287, topic#288, partition#289, offset#290L, timestamp#291, timestampType#292], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@3f70900f,kafka,List(),None,List(),None,Map(kafka.bootstrap.servers -> localhost:9092, subscribe -> tripupdate, startingOffsets -> earliest),None), kafka, [key#279, value#280, topic#281, partition#282, offset#283L, timestamp#284, timestampType#285]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_flattened \u001b[38;5;241m=\u001b[39m \u001b[43mdf_exploded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtripId\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstartTime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimestamp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstopTimeUpdate_exploded.stopSequence\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstopSequence\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstopTimeUpdate_exploded.departure.time\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdeparture_time\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstopTimeUpdate_exploded.stopId\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstopId\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstopTimeUpdate_exploded.scheduleRelationship\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscheduleRelationship\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/dataframe.py:3229\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   3184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   3185\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   3186\u001b[0m \n\u001b[1;32m   3187\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3227\u001b[0m \u001b[38;5;124;03m    +-----+---+\u001b[39;00m\n\u001b[1;32m   3228\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3229\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jcols\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `tripId` cannot be resolved. Did you mean one of the following? [`id`, `tripUpdate`, `timestamp`, `stopTimeUpdate_exploded`].;\n'Project [id#317, 'tripId, 'startTime, timestamp#319, stopTimeUpdate_exploded#498.stopSequence AS stopSequence#503L, stopTimeUpdate_exploded#498.departure.time AS departure_time#504, stopTimeUpdate_exploded#498.stopId AS stopId#505, stopTimeUpdate_exploded#498.scheduleRelationship AS scheduleRelationship#506]\n+- Project [id#317, tripUpdate#318, timestamp#319, stopTimeUpdate_exploded#498]\n   +- Generate explode(tripUpdate#318.stopTimeUpdate), false, [stopTimeUpdate_exploded#498]\n      +- Project [values_json#308.id AS id#317, values_json#308.tripUpdate AS tripUpdate#318, values_json#308.timestamp AS timestamp#319]\n         +- Project [key#286, value#300, topic#288, partition#289, offset#290L, timestamp#291, timestampType#292, from_json(StructField(id,StringType,true), StructField(tripUpdate,StructType(StructField(trip,StructType(StructField(tripId,StringType,true),StructField(startTime,StringType,true),StructField(startDate,StringType,true),StructField(scheduleRelationship,StringType,true),StructField(routeId,StringType,true),StructField(directionId,LongType,true)),true),StructField(stopTimeUpdate,ArrayType(StructType(StructField(stopSequence,LongType,true),StructField(departure,StructType(StructField(time,StringType,true)),true),StructField(stopId,StringType,true),StructField(scheduleRelationship,StringType,true)),true),true)),true), StructField(timestamp,StringType,true), value#300, Some(Europe/Paris)) AS values_json#308]\n            +- Project [key#286, cast(value#287 as string) AS value#300, topic#288, partition#289, offset#290L, timestamp#291, timestampType#292]\n               +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@323e272d, kafka, org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@540d9411, [startingOffsets=earliest, kafka.bootstrap.servers=localhost:9092, subscribe=tripupdate], [key#286, value#287, topic#288, partition#289, offset#290L, timestamp#291, timestampType#292], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@3f70900f,kafka,List(),None,List(),None,Map(kafka.bootstrap.servers -> localhost:9092, subscribe -> tripupdate, startingOffsets -> earliest),None), kafka, [key#279, value#280, topic#281, partition#282, offset#283L, timestamp#284, timestampType#285]\n"
     ]
    }
   ],
   "source": [
    "df_flattened = df_exploded.select(\n",
    "    \"id\",\n",
    "    \"tripId\",\n",
    "    \"startTime\",\n",
    "    \"timestamp\",\n",
    "    F.col(\"stopTimeUpdate_exploded.stopSequence\").alias(\"stopSequence\"),\n",
    "    F.col(\"stopTimeUpdate_exploded.departure.time\").alias(\"departure_time\"),\n",
    "    F.col(\"stopTimeUpdate_exploded.stopId\").alias(\"stopId\"),\n",
    "    F.col(\"stopTimeUpdate_exploded.scheduleRelationship\").alias(\"scheduleRelationship\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/21 00:13:23 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-c684c155-44f7-410c-8563-9015df3c8413. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "24/12/21 00:13:23 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "24/12/21 00:13:23 WARN AdminClientConfig: The configuration 'key.deserializer' was supplied but isn't a known config.\n",
      "24/12/21 00:13:23 WARN AdminClientConfig: The configuration 'value.deserializer' was supplied but isn't a known config.\n",
      "24/12/21 00:13:23 WARN AdminClientConfig: The configuration 'enable.auto.commit' was supplied but isn't a known config.\n",
      "24/12/21 00:13:23 WARN AdminClientConfig: The configuration 'max.poll.records' was supplied but isn't a known config.\n",
      "24/12/21 00:13:23 WARN AdminClientConfig: The configuration 'auto.offset.reset' was supplied but isn't a known config.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+-----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+-----------------------------------+---------------+\n",
      "|id                                       |tripUpdate                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |timestamp|stopTime                           |departure_delay|\n",
      "+-----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+-----------------------------------+---------------+\n",
      "|74_14674_8544710_2024-12-20_50_0_23:10:00|{{74_14674_8544710, 23:10:00, 20241220, SCHEDULED, 5047374, 0}, [{24, {1734730451}, 7513, SCHEDULED}, {25, {1734730506}, 7511, SCHEDULED}, {26, {1734730545}, 7509, SCHEDULED}, {27, {1734730569}, 7507, SCHEDULED}, {28, {1734730593}, 7505, SCHEDULED}, {29, {1734730615}, 7503, SCHEDULED}, {30, {1734730664}, 7501, SCHEDULED}, {31, {1734730719}, 3133, SCHEDULED}, {32, {1734730795}, 3021, SCHEDULED}, {33, {1734730831}, 3019, SCHEDULED}, {34, {1734730869}, 3017, SCHEDULED}, {35, {1734730910}, 3015, SCHEDULED}, {36, {1734730981}, 3013, SCHEDULED}, {37, {1734731030}, 3011, SCHEDULED}, {38, {1734731048}, 3115, SCHEDULED}, {39, {1734731073}, 3009, SCHEDULED}, {40, {1734731142}, 3007, SCHEDULED}, {41, {1734731174}, 3005, SCHEDULED}, {42, {1734731282}, 3003, SCHEDULED}, {43, {1734731321}, 3001, SCHEDULED}, {44, {1734731407}, 0601, SCHEDULED}, {45, {1734731537}, 0523, SCHEDULED}, {46, {1734731609}, 0519, SCHEDULED}, {47, NULL, 0007, SCHEDULED}]}|NULL     |{24, {1734730451}, 7513, SCHEDULED}|NULL           |\n",
      "|74_14674_8544710_2024-12-20_50_0_23:10:00|{{74_14674_8544710, 23:10:00, 20241220, SCHEDULED, 5047374, 0}, [{24, {1734730451}, 7513, SCHEDULED}, {25, {1734730506}, 7511, SCHEDULED}, {26, {1734730545}, 7509, SCHEDULED}, {27, {1734730569}, 7507, SCHEDULED}, {28, {1734730593}, 7505, SCHEDULED}, {29, {1734730615}, 7503, SCHEDULED}, {30, {1734730664}, 7501, SCHEDULED}, {31, {1734730719}, 3133, SCHEDULED}, {32, {1734730795}, 3021, SCHEDULED}, {33, {1734730831}, 3019, SCHEDULED}, {34, {1734730869}, 3017, SCHEDULED}, {35, {1734730910}, 3015, SCHEDULED}, {36, {1734730981}, 3013, SCHEDULED}, {37, {1734731030}, 3011, SCHEDULED}, {38, {1734731048}, 3115, SCHEDULED}, {39, {1734731073}, 3009, SCHEDULED}, {40, {1734731142}, 3007, SCHEDULED}, {41, {1734731174}, 3005, SCHEDULED}, {42, {1734731282}, 3003, SCHEDULED}, {43, {1734731321}, 3001, SCHEDULED}, {44, {1734731407}, 0601, SCHEDULED}, {45, {1734731537}, 0523, SCHEDULED}, {46, {1734731609}, 0519, SCHEDULED}, {47, NULL, 0007, SCHEDULED}]}|NULL     |{25, {1734730506}, 7511, SCHEDULED}|NULL           |\n",
      "|74_14674_8544710_2024-12-20_50_0_23:10:00|{{74_14674_8544710, 23:10:00, 20241220, SCHEDULED, 5047374, 0}, [{24, {1734730451}, 7513, SCHEDULED}, {25, {1734730506}, 7511, SCHEDULED}, {26, {1734730545}, 7509, SCHEDULED}, {27, {1734730569}, 7507, SCHEDULED}, {28, {1734730593}, 7505, SCHEDULED}, {29, {1734730615}, 7503, SCHEDULED}, {30, {1734730664}, 7501, SCHEDULED}, {31, {1734730719}, 3133, SCHEDULED}, {32, {1734730795}, 3021, SCHEDULED}, {33, {1734730831}, 3019, SCHEDULED}, {34, {1734730869}, 3017, SCHEDULED}, {35, {1734730910}, 3015, SCHEDULED}, {36, {1734730981}, 3013, SCHEDULED}, {37, {1734731030}, 3011, SCHEDULED}, {38, {1734731048}, 3115, SCHEDULED}, {39, {1734731073}, 3009, SCHEDULED}, {40, {1734731142}, 3007, SCHEDULED}, {41, {1734731174}, 3005, SCHEDULED}, {42, {1734731282}, 3003, SCHEDULED}, {43, {1734731321}, 3001, SCHEDULED}, {44, {1734731407}, 0601, SCHEDULED}, {45, {1734731537}, 0523, SCHEDULED}, {46, {1734731609}, 0519, SCHEDULED}, {47, NULL, 0007, SCHEDULED}]}|NULL     |{26, {1734730545}, 7509, SCHEDULED}|NULL           |\n",
      "|74_14674_8544710_2024-12-20_50_0_23:10:00|{{74_14674_8544710, 23:10:00, 20241220, SCHEDULED, 5047374, 0}, [{24, {1734730451}, 7513, SCHEDULED}, {25, {1734730506}, 7511, SCHEDULED}, {26, {1734730545}, 7509, SCHEDULED}, {27, {1734730569}, 7507, SCHEDULED}, {28, {1734730593}, 7505, SCHEDULED}, {29, {1734730615}, 7503, SCHEDULED}, {30, {1734730664}, 7501, SCHEDULED}, {31, {1734730719}, 3133, SCHEDULED}, {32, {1734730795}, 3021, SCHEDULED}, {33, {1734730831}, 3019, SCHEDULED}, {34, {1734730869}, 3017, SCHEDULED}, {35, {1734730910}, 3015, SCHEDULED}, {36, {1734730981}, 3013, SCHEDULED}, {37, {1734731030}, 3011, SCHEDULED}, {38, {1734731048}, 3115, SCHEDULED}, {39, {1734731073}, 3009, SCHEDULED}, {40, {1734731142}, 3007, SCHEDULED}, {41, {1734731174}, 3005, SCHEDULED}, {42, {1734731282}, 3003, SCHEDULED}, {43, {1734731321}, 3001, SCHEDULED}, {44, {1734731407}, 0601, SCHEDULED}, {45, {1734731537}, 0523, SCHEDULED}, {46, {1734731609}, 0519, SCHEDULED}, {47, NULL, 0007, SCHEDULED}]}|NULL     |{27, {1734730569}, 7507, SCHEDULED}|NULL           |\n",
      "|74_14674_8544710_2024-12-20_50_0_23:10:00|{{74_14674_8544710, 23:10:00, 20241220, SCHEDULED, 5047374, 0}, [{24, {1734730451}, 7513, SCHEDULED}, {25, {1734730506}, 7511, SCHEDULED}, {26, {1734730545}, 7509, SCHEDULED}, {27, {1734730569}, 7507, SCHEDULED}, {28, {1734730593}, 7505, SCHEDULED}, {29, {1734730615}, 7503, SCHEDULED}, {30, {1734730664}, 7501, SCHEDULED}, {31, {1734730719}, 3133, SCHEDULED}, {32, {1734730795}, 3021, SCHEDULED}, {33, {1734730831}, 3019, SCHEDULED}, {34, {1734730869}, 3017, SCHEDULED}, {35, {1734730910}, 3015, SCHEDULED}, {36, {1734730981}, 3013, SCHEDULED}, {37, {1734731030}, 3011, SCHEDULED}, {38, {1734731048}, 3115, SCHEDULED}, {39, {1734731073}, 3009, SCHEDULED}, {40, {1734731142}, 3007, SCHEDULED}, {41, {1734731174}, 3005, SCHEDULED}, {42, {1734731282}, 3003, SCHEDULED}, {43, {1734731321}, 3001, SCHEDULED}, {44, {1734731407}, 0601, SCHEDULED}, {45, {1734731537}, 0523, SCHEDULED}, {46, {1734731609}, 0519, SCHEDULED}, {47, NULL, 0007, SCHEDULED}]}|NULL     |{28, {1734730593}, 7505, SCHEDULED}|NULL           |\n",
      "|74_14674_8544710_2024-12-20_50_0_23:10:00|{{74_14674_8544710, 23:10:00, 20241220, SCHEDULED, 5047374, 0}, [{24, {1734730451}, 7513, SCHEDULED}, {25, {1734730506}, 7511, SCHEDULED}, {26, {1734730545}, 7509, SCHEDULED}, {27, {1734730569}, 7507, SCHEDULED}, {28, {1734730593}, 7505, SCHEDULED}, {29, {1734730615}, 7503, SCHEDULED}, {30, {1734730664}, 7501, SCHEDULED}, {31, {1734730719}, 3133, SCHEDULED}, {32, {1734730795}, 3021, SCHEDULED}, {33, {1734730831}, 3019, SCHEDULED}, {34, {1734730869}, 3017, SCHEDULED}, {35, {1734730910}, 3015, SCHEDULED}, {36, {1734730981}, 3013, SCHEDULED}, {37, {1734731030}, 3011, SCHEDULED}, {38, {1734731048}, 3115, SCHEDULED}, {39, {1734731073}, 3009, SCHEDULED}, {40, {1734731142}, 3007, SCHEDULED}, {41, {1734731174}, 3005, SCHEDULED}, {42, {1734731282}, 3003, SCHEDULED}, {43, {1734731321}, 3001, SCHEDULED}, {44, {1734731407}, 0601, SCHEDULED}, {45, {1734731537}, 0523, SCHEDULED}, {46, {1734731609}, 0519, SCHEDULED}, {47, NULL, 0007, SCHEDULED}]}|NULL     |{29, {1734730615}, 7503, SCHEDULED}|NULL           |\n",
      "|74_14674_8544710_2024-12-20_50_0_23:10:00|{{74_14674_8544710, 23:10:00, 20241220, SCHEDULED, 5047374, 0}, [{24, {1734730451}, 7513, SCHEDULED}, {25, {1734730506}, 7511, SCHEDULED}, {26, {1734730545}, 7509, SCHEDULED}, {27, {1734730569}, 7507, SCHEDULED}, {28, {1734730593}, 7505, SCHEDULED}, {29, {1734730615}, 7503, SCHEDULED}, {30, {1734730664}, 7501, SCHEDULED}, {31, {1734730719}, 3133, SCHEDULED}, {32, {1734730795}, 3021, SCHEDULED}, {33, {1734730831}, 3019, SCHEDULED}, {34, {1734730869}, 3017, SCHEDULED}, {35, {1734730910}, 3015, SCHEDULED}, {36, {1734730981}, 3013, SCHEDULED}, {37, {1734731030}, 3011, SCHEDULED}, {38, {1734731048}, 3115, SCHEDULED}, {39, {1734731073}, 3009, SCHEDULED}, {40, {1734731142}, 3007, SCHEDULED}, {41, {1734731174}, 3005, SCHEDULED}, {42, {1734731282}, 3003, SCHEDULED}, {43, {1734731321}, 3001, SCHEDULED}, {44, {1734731407}, 0601, SCHEDULED}, {45, {1734731537}, 0523, SCHEDULED}, {46, {1734731609}, 0519, SCHEDULED}, {47, NULL, 0007, SCHEDULED}]}|NULL     |{30, {1734730664}, 7501, SCHEDULED}|NULL           |\n",
      "|74_14674_8544710_2024-12-20_50_0_23:10:00|{{74_14674_8544710, 23:10:00, 20241220, SCHEDULED, 5047374, 0}, [{24, {1734730451}, 7513, SCHEDULED}, {25, {1734730506}, 7511, SCHEDULED}, {26, {1734730545}, 7509, SCHEDULED}, {27, {1734730569}, 7507, SCHEDULED}, {28, {1734730593}, 7505, SCHEDULED}, {29, {1734730615}, 7503, SCHEDULED}, {30, {1734730664}, 7501, SCHEDULED}, {31, {1734730719}, 3133, SCHEDULED}, {32, {1734730795}, 3021, SCHEDULED}, {33, {1734730831}, 3019, SCHEDULED}, {34, {1734730869}, 3017, SCHEDULED}, {35, {1734730910}, 3015, SCHEDULED}, {36, {1734730981}, 3013, SCHEDULED}, {37, {1734731030}, 3011, SCHEDULED}, {38, {1734731048}, 3115, SCHEDULED}, {39, {1734731073}, 3009, SCHEDULED}, {40, {1734731142}, 3007, SCHEDULED}, {41, {1734731174}, 3005, SCHEDULED}, {42, {1734731282}, 3003, SCHEDULED}, {43, {1734731321}, 3001, SCHEDULED}, {44, {1734731407}, 0601, SCHEDULED}, {45, {1734731537}, 0523, SCHEDULED}, {46, {1734731609}, 0519, SCHEDULED}, {47, NULL, 0007, SCHEDULED}]}|NULL     |{31, {1734730719}, 3133, SCHEDULED}|NULL           |\n",
      "|74_14674_8544710_2024-12-20_50_0_23:10:00|{{74_14674_8544710, 23:10:00, 20241220, SCHEDULED, 5047374, 0}, [{24, {1734730451}, 7513, SCHEDULED}, {25, {1734730506}, 7511, SCHEDULED}, {26, {1734730545}, 7509, SCHEDULED}, {27, {1734730569}, 7507, SCHEDULED}, {28, {1734730593}, 7505, SCHEDULED}, {29, {1734730615}, 7503, SCHEDULED}, {30, {1734730664}, 7501, SCHEDULED}, {31, {1734730719}, 3133, SCHEDULED}, {32, {1734730795}, 3021, SCHEDULED}, {33, {1734730831}, 3019, SCHEDULED}, {34, {1734730869}, 3017, SCHEDULED}, {35, {1734730910}, 3015, SCHEDULED}, {36, {1734730981}, 3013, SCHEDULED}, {37, {1734731030}, 3011, SCHEDULED}, {38, {1734731048}, 3115, SCHEDULED}, {39, {1734731073}, 3009, SCHEDULED}, {40, {1734731142}, 3007, SCHEDULED}, {41, {1734731174}, 3005, SCHEDULED}, {42, {1734731282}, 3003, SCHEDULED}, {43, {1734731321}, 3001, SCHEDULED}, {44, {1734731407}, 0601, SCHEDULED}, {45, {1734731537}, 0523, SCHEDULED}, {46, {1734731609}, 0519, SCHEDULED}, {47, NULL, 0007, SCHEDULED}]}|NULL     |{32, {1734730795}, 3021, SCHEDULED}|NULL           |\n",
      "|74_14674_8544710_2024-12-20_50_0_23:10:00|{{74_14674_8544710, 23:10:00, 20241220, SCHEDULED, 5047374, 0}, [{24, {1734730451}, 7513, SCHEDULED}, {25, {1734730506}, 7511, SCHEDULED}, {26, {1734730545}, 7509, SCHEDULED}, {27, {1734730569}, 7507, SCHEDULED}, {28, {1734730593}, 7505, SCHEDULED}, {29, {1734730615}, 7503, SCHEDULED}, {30, {1734730664}, 7501, SCHEDULED}, {31, {1734730719}, 3133, SCHEDULED}, {32, {1734730795}, 3021, SCHEDULED}, {33, {1734730831}, 3019, SCHEDULED}, {34, {1734730869}, 3017, SCHEDULED}, {35, {1734730910}, 3015, SCHEDULED}, {36, {1734730981}, 3013, SCHEDULED}, {37, {1734731030}, 3011, SCHEDULED}, {38, {1734731048}, 3115, SCHEDULED}, {39, {1734731073}, 3009, SCHEDULED}, {40, {1734731142}, 3007, SCHEDULED}, {41, {1734731174}, 3005, SCHEDULED}, {42, {1734731282}, 3003, SCHEDULED}, {43, {1734731321}, 3001, SCHEDULED}, {44, {1734731407}, 0601, SCHEDULED}, {45, {1734731537}, 0523, SCHEDULED}, {46, {1734731609}, 0519, SCHEDULED}, {47, NULL, 0007, SCHEDULED}]}|NULL     |{33, {1734730831}, 3019, SCHEDULED}|NULL           |\n",
      "|74_14674_8544710_2024-12-20_50_0_23:10:00|{{74_14674_8544710, 23:10:00, 20241220, SCHEDULED, 5047374, 0}, [{24, {1734730451}, 7513, SCHEDULED}, {25, {1734730506}, 7511, SCHEDULED}, {26, {1734730545}, 7509, SCHEDULED}, {27, {1734730569}, 7507, SCHEDULED}, {28, {1734730593}, 7505, SCHEDULED}, {29, {1734730615}, 7503, SCHEDULED}, {30, {1734730664}, 7501, SCHEDULED}, {31, {1734730719}, 3133, SCHEDULED}, {32, {1734730795}, 3021, SCHEDULED}, {33, {1734730831}, 3019, SCHEDULED}, {34, {1734730869}, 3017, SCHEDULED}, {35, {1734730910}, 3015, SCHEDULED}, {36, {1734730981}, 3013, SCHEDULED}, {37, {1734731030}, 3011, SCHEDULED}, {38, {1734731048}, 3115, SCHEDULED}, {39, {1734731073}, 3009, SCHEDULED}, {40, {1734731142}, 3007, SCHEDULED}, {41, {1734731174}, 3005, SCHEDULED}, {42, {1734731282}, 3003, SCHEDULED}, {43, {1734731321}, 3001, SCHEDULED}, {44, {1734731407}, 0601, SCHEDULED}, {45, {1734731537}, 0523, SCHEDULED}, {46, {1734731609}, 0519, SCHEDULED}, {47, NULL, 0007, SCHEDULED}]}|NULL     |{34, {1734730869}, 3017, SCHEDULED}|NULL           |\n",
      "|74_14674_8544710_2024-12-20_50_0_23:10:00|{{74_14674_8544710, 23:10:00, 20241220, SCHEDULED, 5047374, 0}, [{24, {1734730451}, 7513, SCHEDULED}, {25, {1734730506}, 7511, SCHEDULED}, {26, {1734730545}, 7509, SCHEDULED}, {27, {1734730569}, 7507, SCHEDULED}, {28, {1734730593}, 7505, SCHEDULED}, {29, {1734730615}, 7503, SCHEDULED}, {30, {1734730664}, 7501, SCHEDULED}, {31, {1734730719}, 3133, SCHEDULED}, {32, {1734730795}, 3021, SCHEDULED}, {33, {1734730831}, 3019, SCHEDULED}, {34, {1734730869}, 3017, SCHEDULED}, {35, {1734730910}, 3015, SCHEDULED}, {36, {1734730981}, 3013, SCHEDULED}, {37, {1734731030}, 3011, SCHEDULED}, {38, {1734731048}, 3115, SCHEDULED}, {39, {1734731073}, 3009, SCHEDULED}, {40, {1734731142}, 3007, SCHEDULED}, {41, {1734731174}, 3005, SCHEDULED}, {42, {1734731282}, 3003, SCHEDULED}, {43, {1734731321}, 3001, SCHEDULED}, {44, {1734731407}, 0601, SCHEDULED}, {45, {1734731537}, 0523, SCHEDULED}, {46, {1734731609}, 0519, SCHEDULED}, {47, NULL, 0007, SCHEDULED}]}|NULL     |{35, {1734730910}, 3015, SCHEDULED}|NULL           |\n",
      "|74_14674_8544710_2024-12-20_50_0_23:10:00|{{74_14674_8544710, 23:10:00, 20241220, SCHEDULED, 5047374, 0}, [{24, {1734730451}, 7513, SCHEDULED}, {25, {1734730506}, 7511, SCHEDULED}, {26, {1734730545}, 7509, SCHEDULED}, {27, {1734730569}, 7507, SCHEDULED}, {28, {1734730593}, 7505, SCHEDULED}, {29, {1734730615}, 7503, SCHEDULED}, {30, {1734730664}, 7501, SCHEDULED}, {31, {1734730719}, 3133, SCHEDULED}, {32, {1734730795}, 3021, SCHEDULED}, {33, {1734730831}, 3019, SCHEDULED}, {34, {1734730869}, 3017, SCHEDULED}, {35, {1734730910}, 3015, SCHEDULED}, {36, {1734730981}, 3013, SCHEDULED}, {37, {1734731030}, 3011, SCHEDULED}, {38, {1734731048}, 3115, SCHEDULED}, {39, {1734731073}, 3009, SCHEDULED}, {40, {1734731142}, 3007, SCHEDULED}, {41, {1734731174}, 3005, SCHEDULED}, {42, {1734731282}, 3003, SCHEDULED}, {43, {1734731321}, 3001, SCHEDULED}, {44, {1734731407}, 0601, SCHEDULED}, {45, {1734731537}, 0523, SCHEDULED}, {46, {1734731609}, 0519, SCHEDULED}, {47, NULL, 0007, SCHEDULED}]}|NULL     |{36, {1734730981}, 3013, SCHEDULED}|NULL           |\n",
      "|74_14674_8544710_2024-12-20_50_0_23:10:00|{{74_14674_8544710, 23:10:00, 20241220, SCHEDULED, 5047374, 0}, [{24, {1734730451}, 7513, SCHEDULED}, {25, {1734730506}, 7511, SCHEDULED}, {26, {1734730545}, 7509, SCHEDULED}, {27, {1734730569}, 7507, SCHEDULED}, {28, {1734730593}, 7505, SCHEDULED}, {29, {1734730615}, 7503, SCHEDULED}, {30, {1734730664}, 7501, SCHEDULED}, {31, {1734730719}, 3133, SCHEDULED}, {32, {1734730795}, 3021, SCHEDULED}, {33, {1734730831}, 3019, SCHEDULED}, {34, {1734730869}, 3017, SCHEDULED}, {35, {1734730910}, 3015, SCHEDULED}, {36, {1734730981}, 3013, SCHEDULED}, {37, {1734731030}, 3011, SCHEDULED}, {38, {1734731048}, 3115, SCHEDULED}, {39, {1734731073}, 3009, SCHEDULED}, {40, {1734731142}, 3007, SCHEDULED}, {41, {1734731174}, 3005, SCHEDULED}, {42, {1734731282}, 3003, SCHEDULED}, {43, {1734731321}, 3001, SCHEDULED}, {44, {1734731407}, 0601, SCHEDULED}, {45, {1734731537}, 0523, SCHEDULED}, {46, {1734731609}, 0519, SCHEDULED}, {47, NULL, 0007, SCHEDULED}]}|NULL     |{37, {1734731030}, 3011, SCHEDULED}|NULL           |\n",
      "|74_14674_8544710_2024-12-20_50_0_23:10:00|{{74_14674_8544710, 23:10:00, 20241220, SCHEDULED, 5047374, 0}, [{24, {1734730451}, 7513, SCHEDULED}, {25, {1734730506}, 7511, SCHEDULED}, {26, {1734730545}, 7509, SCHEDULED}, {27, {1734730569}, 7507, SCHEDULED}, {28, {1734730593}, 7505, SCHEDULED}, {29, {1734730615}, 7503, SCHEDULED}, {30, {1734730664}, 7501, SCHEDULED}, {31, {1734730719}, 3133, SCHEDULED}, {32, {1734730795}, 3021, SCHEDULED}, {33, {1734730831}, 3019, SCHEDULED}, {34, {1734730869}, 3017, SCHEDULED}, {35, {1734730910}, 3015, SCHEDULED}, {36, {1734730981}, 3013, SCHEDULED}, {37, {1734731030}, 3011, SCHEDULED}, {38, {1734731048}, 3115, SCHEDULED}, {39, {1734731073}, 3009, SCHEDULED}, {40, {1734731142}, 3007, SCHEDULED}, {41, {1734731174}, 3005, SCHEDULED}, {42, {1734731282}, 3003, SCHEDULED}, {43, {1734731321}, 3001, SCHEDULED}, {44, {1734731407}, 0601, SCHEDULED}, {45, {1734731537}, 0523, SCHEDULED}, {46, {1734731609}, 0519, SCHEDULED}, {47, NULL, 0007, SCHEDULED}]}|NULL     |{38, {1734731048}, 3115, SCHEDULED}|NULL           |\n",
      "|74_14674_8544710_2024-12-20_50_0_23:10:00|{{74_14674_8544710, 23:10:00, 20241220, SCHEDULED, 5047374, 0}, [{24, {1734730451}, 7513, SCHEDULED}, {25, {1734730506}, 7511, SCHEDULED}, {26, {1734730545}, 7509, SCHEDULED}, {27, {1734730569}, 7507, SCHEDULED}, {28, {1734730593}, 7505, SCHEDULED}, {29, {1734730615}, 7503, SCHEDULED}, {30, {1734730664}, 7501, SCHEDULED}, {31, {1734730719}, 3133, SCHEDULED}, {32, {1734730795}, 3021, SCHEDULED}, {33, {1734730831}, 3019, SCHEDULED}, {34, {1734730869}, 3017, SCHEDULED}, {35, {1734730910}, 3015, SCHEDULED}, {36, {1734730981}, 3013, SCHEDULED}, {37, {1734731030}, 3011, SCHEDULED}, {38, {1734731048}, 3115, SCHEDULED}, {39, {1734731073}, 3009, SCHEDULED}, {40, {1734731142}, 3007, SCHEDULED}, {41, {1734731174}, 3005, SCHEDULED}, {42, {1734731282}, 3003, SCHEDULED}, {43, {1734731321}, 3001, SCHEDULED}, {44, {1734731407}, 0601, SCHEDULED}, {45, {1734731537}, 0523, SCHEDULED}, {46, {1734731609}, 0519, SCHEDULED}, {47, NULL, 0007, SCHEDULED}]}|NULL     |{39, {1734731073}, 3009, SCHEDULED}|NULL           |\n",
      "|74_14674_8544710_2024-12-20_50_0_23:10:00|{{74_14674_8544710, 23:10:00, 20241220, SCHEDULED, 5047374, 0}, [{24, {1734730451}, 7513, SCHEDULED}, {25, {1734730506}, 7511, SCHEDULED}, {26, {1734730545}, 7509, SCHEDULED}, {27, {1734730569}, 7507, SCHEDULED}, {28, {1734730593}, 7505, SCHEDULED}, {29, {1734730615}, 7503, SCHEDULED}, {30, {1734730664}, 7501, SCHEDULED}, {31, {1734730719}, 3133, SCHEDULED}, {32, {1734730795}, 3021, SCHEDULED}, {33, {1734730831}, 3019, SCHEDULED}, {34, {1734730869}, 3017, SCHEDULED}, {35, {1734730910}, 3015, SCHEDULED}, {36, {1734730981}, 3013, SCHEDULED}, {37, {1734731030}, 3011, SCHEDULED}, {38, {1734731048}, 3115, SCHEDULED}, {39, {1734731073}, 3009, SCHEDULED}, {40, {1734731142}, 3007, SCHEDULED}, {41, {1734731174}, 3005, SCHEDULED}, {42, {1734731282}, 3003, SCHEDULED}, {43, {1734731321}, 3001, SCHEDULED}, {44, {1734731407}, 0601, SCHEDULED}, {45, {1734731537}, 0523, SCHEDULED}, {46, {1734731609}, 0519, SCHEDULED}, {47, NULL, 0007, SCHEDULED}]}|NULL     |{40, {1734731142}, 3007, SCHEDULED}|NULL           |\n",
      "|74_14674_8544710_2024-12-20_50_0_23:10:00|{{74_14674_8544710, 23:10:00, 20241220, SCHEDULED, 5047374, 0}, [{24, {1734730451}, 7513, SCHEDULED}, {25, {1734730506}, 7511, SCHEDULED}, {26, {1734730545}, 7509, SCHEDULED}, {27, {1734730569}, 7507, SCHEDULED}, {28, {1734730593}, 7505, SCHEDULED}, {29, {1734730615}, 7503, SCHEDULED}, {30, {1734730664}, 7501, SCHEDULED}, {31, {1734730719}, 3133, SCHEDULED}, {32, {1734730795}, 3021, SCHEDULED}, {33, {1734730831}, 3019, SCHEDULED}, {34, {1734730869}, 3017, SCHEDULED}, {35, {1734730910}, 3015, SCHEDULED}, {36, {1734730981}, 3013, SCHEDULED}, {37, {1734731030}, 3011, SCHEDULED}, {38, {1734731048}, 3115, SCHEDULED}, {39, {1734731073}, 3009, SCHEDULED}, {40, {1734731142}, 3007, SCHEDULED}, {41, {1734731174}, 3005, SCHEDULED}, {42, {1734731282}, 3003, SCHEDULED}, {43, {1734731321}, 3001, SCHEDULED}, {44, {1734731407}, 0601, SCHEDULED}, {45, {1734731537}, 0523, SCHEDULED}, {46, {1734731609}, 0519, SCHEDULED}, {47, NULL, 0007, SCHEDULED}]}|NULL     |{41, {1734731174}, 3005, SCHEDULED}|NULL           |\n",
      "|74_14674_8544710_2024-12-20_50_0_23:10:00|{{74_14674_8544710, 23:10:00, 20241220, SCHEDULED, 5047374, 0}, [{24, {1734730451}, 7513, SCHEDULED}, {25, {1734730506}, 7511, SCHEDULED}, {26, {1734730545}, 7509, SCHEDULED}, {27, {1734730569}, 7507, SCHEDULED}, {28, {1734730593}, 7505, SCHEDULED}, {29, {1734730615}, 7503, SCHEDULED}, {30, {1734730664}, 7501, SCHEDULED}, {31, {1734730719}, 3133, SCHEDULED}, {32, {1734730795}, 3021, SCHEDULED}, {33, {1734730831}, 3019, SCHEDULED}, {34, {1734730869}, 3017, SCHEDULED}, {35, {1734730910}, 3015, SCHEDULED}, {36, {1734730981}, 3013, SCHEDULED}, {37, {1734731030}, 3011, SCHEDULED}, {38, {1734731048}, 3115, SCHEDULED}, {39, {1734731073}, 3009, SCHEDULED}, {40, {1734731142}, 3007, SCHEDULED}, {41, {1734731174}, 3005, SCHEDULED}, {42, {1734731282}, 3003, SCHEDULED}, {43, {1734731321}, 3001, SCHEDULED}, {44, {1734731407}, 0601, SCHEDULED}, {45, {1734731537}, 0523, SCHEDULED}, {46, {1734731609}, 0519, SCHEDULED}, {47, NULL, 0007, SCHEDULED}]}|NULL     |{42, {1734731282}, 3003, SCHEDULED}|NULL           |\n",
      "|74_14674_8544710_2024-12-20_50_0_23:10:00|{{74_14674_8544710, 23:10:00, 20241220, SCHEDULED, 5047374, 0}, [{24, {1734730451}, 7513, SCHEDULED}, {25, {1734730506}, 7511, SCHEDULED}, {26, {1734730545}, 7509, SCHEDULED}, {27, {1734730569}, 7507, SCHEDULED}, {28, {1734730593}, 7505, SCHEDULED}, {29, {1734730615}, 7503, SCHEDULED}, {30, {1734730664}, 7501, SCHEDULED}, {31, {1734730719}, 3133, SCHEDULED}, {32, {1734730795}, 3021, SCHEDULED}, {33, {1734730831}, 3019, SCHEDULED}, {34, {1734730869}, 3017, SCHEDULED}, {35, {1734730910}, 3015, SCHEDULED}, {36, {1734730981}, 3013, SCHEDULED}, {37, {1734731030}, 3011, SCHEDULED}, {38, {1734731048}, 3115, SCHEDULED}, {39, {1734731073}, 3009, SCHEDULED}, {40, {1734731142}, 3007, SCHEDULED}, {41, {1734731174}, 3005, SCHEDULED}, {42, {1734731282}, 3003, SCHEDULED}, {43, {1734731321}, 3001, SCHEDULED}, {44, {1734731407}, 0601, SCHEDULED}, {45, {1734731537}, 0523, SCHEDULED}, {46, {1734731609}, 0519, SCHEDULED}, {47, NULL, 0007, SCHEDULED}]}|NULL     |{43, {1734731321}, 3001, SCHEDULED}|NULL           |\n",
      "+-----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+-----------------------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ala/.local/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/ala/.local/lib/python3.10/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[43mdf_with_delay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriteStream\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputMode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mappend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconsole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtruncate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfalse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m----> 6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/streaming/query.py:221\u001b[0m, in \u001b[0;36mStreamingQuery.awaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsq\u001b[38;5;241m.\u001b[39mawaitTermination(\u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_with_delay.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .start() \\\n",
    "    .awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
